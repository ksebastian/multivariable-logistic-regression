{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Multi-Variable Logistic Regression and Classification Matrix\n",
    "\n",
    "_Authors: Sam Stack(DC)_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise Objectives**\n",
    "- Hand on experience using Multi-Variable Logistic Regression\n",
    "- Review and Exploration of the Classification Matrix and its evaluation Metrics\n",
    "- Introduction to One vs. One and One vs. Rest Classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lets get some data.**\n",
    "One of the most popular classification datasets for Machine learning is the Iris Dataset, which can be loaded directly from `sklearn.datasets`\n",
    "- Sklearn datasets are imported as dictionaries and use keys to access specific aspects.\n",
    "    - `iris.data` : actual matrix of observations\n",
    "    - `iris.target` : target column for classification\n",
    "    - `iris.feature_names` :  column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-08T05:53:53.955119Z",
     "start_time": "2020-12-08T05:53:49.292811Z"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn import datasets # import built-in datasets\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and examine data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.utils._bunch.Bunch'>\n",
      "====================================================================================================\n",
      "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])\n"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# examine what we loaded\n",
    "print(type(iris))\n",
    "\n",
    "print('='*100)\n",
    "\n",
    "#looks like a dictionary\n",
    "print(iris.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_names: ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "====================================================================================================\n",
      "target_names: ['setosa' 'versicolor' 'virginica']\n",
      "====================================================================================================\n",
      "DESCR: .. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "                \n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
      "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
      "Machine Learning Repository, which has two wrong data points.\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Examine the data\n",
    "print(\"feature_names:\", iris['feature_names'])\n",
    "print('='*100)\n",
    "print(\"target_names:\", iris['target_names'])\n",
    "print('='*100)\n",
    "print(\"DESCR:\", iris['DESCR'])\n",
    "print('='*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the values\n",
    "X = pd.DataFrame(iris.data, columns = iris.feature_names)\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                5.1               3.5                1.4               0.2\n",
       "1                4.9               3.0                1.4               0.2\n",
       "2                4.7               3.2                1.3               0.2\n",
       "3                4.6               3.1                1.5               0.2\n",
       "4                5.0               3.6                1.4               0.2"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# features\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# target values\n",
    "print(type(y))\n",
    "y[:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Break down of classes**  \n",
    "0 : Setosa  \n",
    "1 : Versicolour  \n",
    "2 : Virginica  \n",
    "\n",
    "----\n",
    "\n",
    "**Modelling**\n",
    "This data is extreamly neat and tidy so no cleaning necessary and we can get right into modelling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the relationship of the features to the target species\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Species')\n",
    "\n",
    "pltX = X.loc[:, 'sepal length (cm)']\n",
    "pltY = y\n",
    "plt.scatter(pltX, pltY, color='yellow', label='sepal length')\n",
    "\n",
    "pltX = X.loc[:, 'sepal width (cm)']\n",
    "pltY = y\n",
    "plt.scatter(pltX, pltY, color='orange', label='sepal width')\n",
    "\n",
    "pltX = X.loc[:, 'petal length (cm)']\n",
    "pltY = y\n",
    "plt.scatter(pltX, pltY, color='blue', label='petal length')\n",
    "\n",
    "pltX = X.loc[:, 'petal width (cm)']\n",
    "pltY = y\n",
    "plt.scatter(pltX, pltY, color='green', label='petal width')\n",
    "\n",
    "plt.legend(loc=4, prop={'size': 8})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### # Model the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data to 80% training and 20% testing\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model\n",
    "model = LogisticRegression()\n",
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [1 1 0 1 2 2 0 0 2 2 2 0 2 1 2 1 2 0 1 2 0 0 2 0 1 1 1 1 2 2]\n",
      "====================================================================================================\n",
      "Actuals    : [1 1 0 1 2 2 0 0 2 2 2 0 2 1 2 1 2 0 1 2 0 0 2 0 2 2 1 1 2 2]\n"
     ]
    }
   ],
   "source": [
    "# model.predict\n",
    "predictions = model.predict(x_test)\n",
    "\n",
    "print(\"Predictions:\", predictions)\n",
    "print('='*100)\n",
    "print(\"Actuals    :\", y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions look pretty good!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8  0  0]\n",
      " [ 0  8  0]\n",
      " [ 0  2 12]]\n"
     ]
    }
   ],
   "source": [
    "# evaluated model preformance with a confusion matrix.\n",
    "confusion_matrix = confusion_matrix(y_test, predictions)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt the matrix\n",
    "plt.matshow(confusion_matrix, cmap=plt.cm.summer)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a multivariable confusion matrix, some of our labellings (True Pos., True Neg., False Pos., False Neg.) get a little warped.  We are no longer predicting one class from a null class we are classifiying into 3 distinguished classes.  \n",
    "\n",
    "The **True** diagonal stays the same as these are properly classified observations.  \n",
    "\n",
    "\n",
    "|   Actual/Pred | Class 0 | Class 1  | Class 2 |\n",
    "| --- | ------- |:--------:| -------:|\n",
    "| **Pred Class 0**  | 15      | 0        | 0       |\n",
    "| **Pred Class 1**    | 0       | 11       |   0     |\n",
    "| **Pred Class 2**    | 0       | 1        |    11   |\n",
    "\n",
    "\n",
    "It is better to stick with True and False labels with multi-class to avoid ...[_Confusion_](https://www.youtube.com/watch?v=bcYppAs6ZdI)\n",
    "\n",
    "If you need to reffer to a False Positive or True Negative it is better to first select a specific class, such as `Class 2 ` and refer to classification or misclassification relative to said choosen class instead of the set of all classes as a whole. \n",
    "\n",
    "Example:\n",
    "    _True Negatives relative to Class 2 are True Positives for Class 0 and Class 1._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Speaking of our Classes?  How are probabilities calculated with multi class?\n",
    "- Are they Probability of `Class 0` vs. `Not Class 0`?\n",
    "- Or Probability of `Class 0` vs. `Class 1` vs. `Class 2` ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.80708412e-02 9.19387412e-01 6.25417472e-02]\n",
      " [6.42326622e-03 9.09500963e-01 8.40757710e-02]\n",
      " [9.64759699e-01 3.52400510e-02 2.49518832e-07]\n",
      " [2.86599239e-03 8.14512228e-01 1.82621780e-01]\n",
      " [1.08490508e-04 2.77779171e-01 7.22112338e-01]\n",
      " [2.22835174e-06 7.37233387e-03 9.92625438e-01]\n",
      " [9.43217689e-01 5.67814949e-02 8.15766342e-07]\n",
      " [9.78582366e-01 2.14175354e-02 9.90068602e-08]\n",
      " [1.14410606e-04 1.60398542e-01 8.39487047e-01]\n",
      " [1.14978741e-05 3.52886503e-02 9.64699852e-01]\n",
      " [4.62372616e-06 2.05902743e-02 9.79405102e-01]\n",
      " [9.81549664e-01 1.84502648e-02 7.07531720e-08]\n",
      " [2.27913897e-05 2.63498465e-02 9.73627362e-01]\n",
      " [3.54261343e-03 7.88499715e-01 2.07957671e-01]\n",
      " [1.59581736e-04 1.42951228e-01 8.56889190e-01]\n",
      " [8.20789778e-03 9.33016155e-01 5.87759470e-02]\n",
      " [2.05036061e-03 4.80771658e-01 5.17177982e-01]\n",
      " [9.71310036e-01 2.86898409e-02 1.23559601e-07]\n",
      " [4.46805330e-03 7.04449351e-01 2.91082596e-01]\n",
      " [9.86567312e-06 7.29723208e-02 9.27017813e-01]\n",
      " [9.62665597e-01 3.73342608e-02 1.41918710e-07]\n",
      " [9.54467778e-01 4.55318857e-02 3.36454323e-07]\n",
      " [8.37100919e-06 2.99266311e-02 9.70064998e-01]\n",
      " [9.68541896e-01 3.14580068e-02 9.75605117e-08]\n",
      " [5.38752197e-04 5.56938194e-01 4.42523054e-01]\n",
      " [1.39710965e-03 5.03299905e-01 4.95302986e-01]\n",
      " [5.31743641e-03 8.26032866e-01 1.68649698e-01]\n",
      " [1.85219788e-02 9.49179723e-01 3.22982979e-02]\n",
      " [2.19870963e-04 1.97054095e-01 8.02726034e-01]\n",
      " [6.85948470e-04 2.92931637e-01 7.06382415e-01]]\n"
     ]
    }
   ],
   "source": [
    "# use predict_proba to find out.\n",
    "probability = model.predict_proba(x_test)\n",
    "print(probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "print(probability.shape[0])\n",
    "print(x_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.018071</td>\n",
       "      <td>0.919387</td>\n",
       "      <td>6.254175e-02</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.006423</td>\n",
       "      <td>0.909501</td>\n",
       "      <td>8.407577e-02</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.964760</td>\n",
       "      <td>0.035240</td>\n",
       "      <td>2.495188e-07</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002866</td>\n",
       "      <td>0.814512</td>\n",
       "      <td>1.826218e-01</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.277779</td>\n",
       "      <td>7.221123e-01</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.007372</td>\n",
       "      <td>9.926254e-01</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.943218</td>\n",
       "      <td>0.056781</td>\n",
       "      <td>8.157663e-07</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.978582</td>\n",
       "      <td>0.021418</td>\n",
       "      <td>9.900686e-08</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.160399</td>\n",
       "      <td>8.394870e-01</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.035289</td>\n",
       "      <td>9.646999e-01</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1             2  sum\n",
       "0  0.018071  0.919387  6.254175e-02  1.0\n",
       "1  0.006423  0.909501  8.407577e-02  1.0\n",
       "2  0.964760  0.035240  2.495188e-07  1.0\n",
       "3  0.002866  0.814512  1.826218e-01  1.0\n",
       "4  0.000108  0.277779  7.221123e-01  1.0\n",
       "5  0.000002  0.007372  9.926254e-01  1.0\n",
       "6  0.943218  0.056781  8.157663e-07  1.0\n",
       "7  0.978582  0.021418  9.900686e-08  1.0\n",
       "8  0.000114  0.160399  8.394870e-01  1.0\n",
       "9  0.000011  0.035289  9.646999e-01  1.0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# readable data frame of probablity results\n",
    "probability_df = pd.DataFrame(probability, columns=model.classes_)\n",
    "probability_df['sum'] = probability_df.sum(axis=1)\n",
    "probability_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>sum</th>\n",
       "      <th>predicted_class</th>\n",
       "      <th>actual_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.018071</td>\n",
       "      <td>0.919387</td>\n",
       "      <td>6.254175e-02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.006423</td>\n",
       "      <td>0.909501</td>\n",
       "      <td>8.407577e-02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.964760</td>\n",
       "      <td>0.035240</td>\n",
       "      <td>2.495188e-07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002866</td>\n",
       "      <td>0.814512</td>\n",
       "      <td>1.826218e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.277779</td>\n",
       "      <td>7.221123e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.007372</td>\n",
       "      <td>9.926254e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.943218</td>\n",
       "      <td>0.056781</td>\n",
       "      <td>8.157663e-07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.978582</td>\n",
       "      <td>0.021418</td>\n",
       "      <td>9.900686e-08</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.160399</td>\n",
       "      <td>8.394870e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.035289</td>\n",
       "      <td>9.646999e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1             2  sum  predicted_class  actual_class\n",
       "0  0.018071  0.919387  6.254175e-02  1.0                1             1\n",
       "1  0.006423  0.909501  8.407577e-02  1.0                1             1\n",
       "2  0.964760  0.035240  2.495188e-07  1.0                0             0\n",
       "3  0.002866  0.814512  1.826218e-01  1.0                1             1\n",
       "4  0.000108  0.277779  7.221123e-01  1.0                2             2\n",
       "5  0.000002  0.007372  9.926254e-01  1.0                2             2\n",
       "6  0.943218  0.056781  8.157663e-07  1.0                0             0\n",
       "7  0.978582  0.021418  9.900686e-08  1.0                0             0\n",
       "8  0.000114  0.160399  8.394870e-01  1.0                2             2\n",
       "9  0.000011  0.035289  9.646999e-01  1.0                2             2"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add predictions and actuals\n",
    "probability_df['predicted_class'] = predictions\n",
    "probability_df['actual_class'] = y_test #.to_frame().reset_index().drop(columns='index')\n",
    "probability_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like our probabilities of each class all add up to 1, so it is like `Class 0` vs. `Class 1` vs. `Class 2`.\n",
    "\n",
    "What if we wanted to create a logistic regression that has `Class 0` vs. `Class 1` & `Class 2` or just `Class 0` vs. `Class 2`?  We will cover that in a bit, but first more evaluation metrics.\n",
    "\n",
    "---\n",
    "\n",
    "**Classification Reports/Matrix**\n",
    "\n",
    "Classification reports are another means of evauliation classification models and return a few metrics that are based on True Positives, False Positives and False Negatives.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "# Accuracy score\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         8\n",
      "           1       0.80      1.00      0.89         8\n",
      "           2       1.00      0.86      0.92        14\n",
      "\n",
      "    accuracy                           0.93        30\n",
      "   macro avg       0.93      0.95      0.94        30\n",
      "weighted avg       0.95      0.93      0.93        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check precision, recall, f1-score \n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Precision**  \n",
    "- \"How many of the items selected are relevant.\"\n",
    "- Of the items placed into a class, how many of the are True Positives.\n",
    "\n",
    "\n",
    "$$\\frac{True Positives}{True Positives + False Positives}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recall**  \n",
    "- \"How many of the relevant items are selected.\"\n",
    "- Of the items that were suppose to be placed into a class, how many did we accurately place.\n",
    "\n",
    "\n",
    "$$\\frac{True Positives}{True Positives + False Negatives}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**F1-Score**\n",
    "\n",
    "F1 exists on a range of 0 - 1 where 0 is just aweful and 1 is perfection.\n",
    "F1 is considered a harmonic mean as it averages Precision and Recall.  With classification models you often times have to chooise what kind of error you are willing to increase in order to reduce the other and thus you may want to optimize Precision or Recall accordingly.  If you are uncertain which you should optimize, F1 score may be the metric of choice.\n",
    "\n",
    "$$2*\\frac{precision * recall}{precision + recall}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Support**\n",
    "Number of true observations in given class.  The count of possible true observations.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro to Ensembling\n",
    "\n",
    "Earlier we talked about building models relative to class combinations.  Distinguishing One class from all other classes or just One specific class from another specific class.  These goals are possible with Logistic Regression.\n",
    "\n",
    "Up until this point we have used one model, but there are also Machine Learning methods that involve combining several models to come to a more refined conclusion, commonly reffered to as Ensemble Methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Vs. Rest Classification.\n",
    "\n",
    "One vs. Rest Classification is a method that builds an individual model for each class to try to distingush said specific class from the rest of the classes.  Since we are only focusing on one class, `Class 1` these classfiers will group `Class2`, `Class3`, `Class4` into a single class of `Not Class 1`.  Same all the way through for the rest of the classes.\n",
    "\n",
    "1 - Class1 vs. Class2, Class3, Class4  \n",
    "2 - Class2 vs. Class1, Class3, Class4  \n",
    "3 - Class3 vs. Class1, Class2, Class4   \n",
    "4 - Class4 vs. Class1, Class2, Class3  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Vs. One Classification.\n",
    "\n",
    "We train a model for every set of classes.  As more classes are added this becomes more computationally expense.  \n",
    "\n",
    "1 - Class1 vs. Class2  \n",
    "2 - Class1 vs. Class3  \n",
    "3 - Class1 vs. Class4  \n",
    "4 - Class2 vs. Class3  \n",
    "5 - Class2 vs. Class4  \n",
    "6 - Class3 vs. Class4  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One Vs. Rest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ensemble meth\n",
    "od\n",
    "# instantiate choose model\n",
    "LR = LogisticRegression()\n",
    "# place the model in the ensembler\n",
    "OVC = OneVsRestClassifier(LR)\n",
    "# use the ensemble method like a normal sklearn model.\n",
    "OVC.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# you can use the train test split you created earlier or do a new TTS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the .predict and confusion matrix the same way\n",
    "y_pred = OVC.predict(x_test)\n",
    "\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One Vs. One Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = LogisticRegression()\n",
    "# OvO works the same as OvR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prediction and evaluate confusion matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One Vs. One/Rest Classifiers are not restricted to fitting using Logistic Regression.  With SKLearn, any type of Classification model can be placed into the One Vs X classification ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
